{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrzUTW5CxPnZ"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vosk\n",
        "!wget https://alphacephei.com/kaldi/models/vosk-model-en-us-0.21.zip\n",
        "!unzip /content/vosk-model-en-us-0.21.zip"
      ],
      "metadata": {
        "id": "05xV5-IRVj_r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df84c4fa-cbbd-4c2b-ead2-b514d389c4c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vosk\n",
            "  Downloading vosk-0.3.37-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from vosk) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->vosk) (2.21)\n",
            "Installing collected packages: vosk\n",
            "Successfully installed vosk-0.3.37\n",
            "--2022-04-28 12:48:07--  https://alphacephei.com/kaldi/models/vosk-model-en-us-0.21.zip\n",
            "Resolving alphacephei.com (alphacephei.com)... 188.40.21.16, 2a01:4f8:13a:279f::2\n",
            "Connecting to alphacephei.com (alphacephei.com)|188.40.21.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1752830350 (1.6G) [application/zip]\n",
            "Saving to: ‘vosk-model-en-us-0.21.zip’\n",
            "\n",
            "vosk-model-en-us-0. 100%[===================>]   1.63G  26.1MB/s    in 65s     \n",
            "\n",
            "2022-04-28 12:49:12 (25.9 MB/s) - ‘vosk-model-en-us-0.21.zip’ saved [1752830350/1752830350]\n",
            "\n",
            "Archive:  /content/vosk-model-en-us-0.21.zip\n",
            "   creating: vosk-model-en-us-0.21/\n",
            "   creating: vosk-model-en-us-0.21/am/\n",
            "  inflating: vosk-model-en-us-0.21/am/final.mdl  \n",
            "  inflating: vosk-model-en-us-0.21/am/tree  \n",
            "   creating: vosk-model-en-us-0.21/ivector/\n",
            "  inflating: vosk-model-en-us-0.21/ivector/final.dubm  \n",
            "  inflating: vosk-model-en-us-0.21/ivector/final.ie  \n",
            "  inflating: vosk-model-en-us-0.21/ivector/final.mat  \n",
            "  inflating: vosk-model-en-us-0.21/ivector/splice.conf  \n",
            "  inflating: vosk-model-en-us-0.21/ivector/global_cmvn.stats  \n",
            " extracting: vosk-model-en-us-0.21/ivector/online_cmvn.conf  \n",
            "  inflating: vosk-model-en-us-0.21/README  \n",
            "   creating: vosk-model-en-us-0.21/conf/\n",
            "  inflating: vosk-model-en-us-0.21/conf/mfcc.conf  \n",
            "  inflating: vosk-model-en-us-0.21/conf/model.conf  \n",
            "   creating: vosk-model-en-us-0.21/graph/\n",
            "  inflating: vosk-model-en-us-0.21/graph/disambig_tid.int  \n",
            "   creating: vosk-model-en-us-0.21/graph/phones/\n",
            " extracting: vosk-model-en-us-0.21/graph/phones/optional_silence.int  \n",
            " extracting: vosk-model-en-us-0.21/graph/phones/optional_silence.csl  \n",
            "  inflating: vosk-model-en-us-0.21/graph/phones/align_lexicon.int  \n",
            " extracting: vosk-model-en-us-0.21/graph/phones/silence.csl  \n",
            "  inflating: vosk-model-en-us-0.21/graph/phones/align_lexicon.txt  \n",
            " extracting: vosk-model-en-us-0.21/graph/phones/optional_silence.txt  \n",
            "  inflating: vosk-model-en-us-0.21/graph/phones/disambig.txt  \n",
            "  inflating: vosk-model-en-us-0.21/graph/phones/word_boundary.int  \n",
            "  inflating: vosk-model-en-us-0.21/graph/phones/disambig.int  \n",
            "  inflating: vosk-model-en-us-0.21/graph/phones/word_boundary.txt  \n",
            "  inflating: vosk-model-en-us-0.21/graph/HCLG.fst  \n",
            " extracting: vosk-model-en-us-0.21/graph/num_pdfs  \n",
            "  inflating: vosk-model-en-us-0.21/graph/phones.txt  \n",
            "  inflating: vosk-model-en-us-0.21/graph/words.txt  \n",
            "   creating: vosk-model-en-us-0.21/rnnlm/\n",
            "  inflating: vosk-model-en-us-0.21/rnnlm/word_feats.txt  \n",
            "  inflating: vosk-model-en-us-0.21/rnnlm/special_symbol_opts.conf  \n",
            "  inflating: vosk-model-en-us-0.21/rnnlm/special_symbol_opts.txt  \n",
            "  inflating: vosk-model-en-us-0.21/rnnlm/feat_embedding.final.mat  \n",
            "  inflating: vosk-model-en-us-0.21/rnnlm/final.raw  \n",
            "   creating: vosk-model-en-us-0.21/rescore/\n",
            "  inflating: vosk-model-en-us-0.21/rescore/G.carpa  \n",
            "  inflating: vosk-model-en-us-0.21/rescore/G.fst  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIwvwTjPxS9v"
      },
      "outputs": [],
      "source": [
        "import wave\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "from vosk import Model, KaldiRecognizer, SetLogLevel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3XhQBUWzw4K"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKdfIn7n0C00"
      },
      "source": [
        "### Word Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZPGfAGH266k"
      },
      "outputs": [],
      "source": [
        "class Word:\n",
        "    ''' A class representing a word from the JSON format for vosk speech recognition API '''\n",
        "\n",
        "    def __init__(self, dict):\n",
        "        '''\n",
        "        Parameters:\n",
        "          dict (dict) dictionary from JSON, containing:\n",
        "            conf (float): degree of confidence, from 0 to 1\n",
        "            end (float): end time of the pronouncing the word, in seconds\n",
        "            start (float): start time of the pronouncing the word, in seconds\n",
        "            word (str): recognized word\n",
        "        '''\n",
        "\n",
        "        self.conf = dict[\"conf\"]\n",
        "        self.end = dict[\"end\"]\n",
        "        self.start = dict[\"start\"]\n",
        "        self.word = dict[\"word\"]\n",
        "\n",
        "    def to_string(self):\n",
        "        ''' Returns a string describing this instance '''\n",
        "        return \"{:20} from {:.2f} sec to {:.2f} sec, confidence is {:.2f}%\".format(\n",
        "            self.word, self.start, self.end, self.conf*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0PdM38gz9t_"
      },
      "source": [
        "### Getting Data from Video-Recommendation-System.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/atishaye/Video-Recommendation-System.git"
      ],
      "metadata": {
        "id": "A3m4eSmLXDse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d0ceb8-eac0-47b5-c0fd-62154a83da9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Video-Recommendation-System'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 44 (delta 1), reused 11 (delta 0), pack-reused 30\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n",
            "Checking out files: 100% (30/30), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86idc6cM6WZT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "8fa8f4ad-77d2-4f3d-c41a-e4c74738b451"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['/content/Video-Recommendation-System/Data/Audio Files/00_astronomy.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/01_white_dwarf.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/02_chimp.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/03_crypto.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/04_crypto_tax.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/05_crypto_means.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/06_digital_token.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/07_cryptocurrency.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/08_dodo.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/09_dolphin.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/10_elephant.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/11_fd_mutual_finance.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/12_finance.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/13_jeffrey_archer.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/14_mammoth.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/15_murakami.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/16_mutual_funds.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/17_paulo_coelho.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/18_penguin.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/19_animal_farm.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/20_shakespeare.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/21_snow_bunting.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/22_super_nova.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/23_vaccine_news.wav',\n",
              " '/content/Video-Recommendation-System/Data/Audio Files/24_whale.wav']"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n"
          ]
        }
      ],
      "source": [
        "# get all files\n",
        "import os\n",
        "transcripts=os.listdir('/content/Video-Recommendation-System/Data/Audio Files')\n",
        "for i in range(len(transcripts)):\n",
        "  transcripts[i]='/content/Video-Recommendation-System/Data/Audio Files/'+transcripts[i]\n",
        "transcripts=sorted(transcripts)\n",
        "display(transcripts)\n",
        "dataset_size=len(transcripts)\n",
        "print(dataset_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ss0h0dmHUZN"
      },
      "source": [
        "### TimeStamping Transcripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "NAp61wE73Izn",
        "outputId": "8d667c74-dbc1-4837-b95c-555a8b599469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamping for /content/Video-Recommendation-System/Data/Audio Files/22_super_nova.wav begin!\n",
            "Timestamping for Transcript 22 done!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-94da61b69a5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Timestamping for Transcript'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mmaster_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timestamped_transcripts.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mmaster_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaster_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# master_df.to_csv('timestamped_transcripts.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'timestamped_transcripts.csv'"
          ]
        }
      ],
      "source": [
        "model_path = \"./vosk-model-en-us-0.21\"\n",
        "\n",
        "i=22\n",
        "\n",
        "audio_filename = transcripts[i]\n",
        "print('Timestamping for', transcripts[i], 'begin!')\n",
        "model = Model(model_path)\n",
        "wf = wave.open(audio_filename, \"rb\")\n",
        "rec = KaldiRecognizer(model, wf.getframerate())\n",
        "rec.SetWords(True)\n",
        "\n",
        "# get the list of JSON dictionaries\n",
        "results = []\n",
        "# recognize speech using vosk model\n",
        "while True:\n",
        "    data = wf.readframes(4000)\n",
        "    if len(data) == 0:\n",
        "        break\n",
        "    if rec.AcceptWaveform(data):\n",
        "        part_result = json.loads(rec.Result())\n",
        "        results.append(part_result)\n",
        "part_result = json.loads(rec.FinalResult())\n",
        "results.append(part_result)\n",
        "\n",
        "# convert list of JSON dictionaries to list of 'Word' objects\n",
        "list_of_Words = []\n",
        "for sentence in results:\n",
        "    if len(sentence) == 1:\n",
        "        # sometimes there are bugs in recognition \n",
        "        # and it returns an empty dictionary\n",
        "        # {'text': ''}\n",
        "        continue\n",
        "    for obj in sentence['result']:\n",
        "        w = Word(obj)  # create custom Word object\n",
        "        list_of_Words.append(w)  # and add it to list\n",
        "\n",
        "wf.close()  # close audiofile\n",
        "\n",
        "# output to the screen\n",
        "# for word in list_of_Words:\n",
        "#     print(word.to_string())\n",
        "\n",
        "master_list=[]\n",
        "for j in range(len(list_of_Words)):\n",
        "  l=list_of_Words[j].to_string().split(' ')\n",
        "  while \"\" in l:\n",
        "    l.remove(\"\")\n",
        "  master_list.append(l)\n",
        "\n",
        "df=pd.DataFrame(master_list)\n",
        "df=df.drop([1,3,4,6,7,8],axis=1)\n",
        "transcript_id=[i for _ in range(len(master_list))]\n",
        "df.insert(0,'transcript_id',transcript_id)\n",
        "df.columns=['transcript_id','word', 'start_timestamp(sec)', 'end_timestamp(sec)', 'confidence']\n",
        "print('Timestamping for Transcript',i,'done!')\n",
        "\n",
        "master_df=pd.read_csv('timestamped_transcripts.csv')\n",
        "master_df=master_df.append(df,ignore_index=True)\n",
        "# master_df.to_csv('timestamped_transcripts.csv')\n",
        "# master_df=pd.read_csv('timestamped_transcripts.csv')\n",
        "# master_df.drop(master_df.columns[[0, 1]], axis = 1, inplace = True)\n",
        "master_df.to_csv('timestamped_transcripts.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('timestamped_transcripts.csv') \n",
        "master_df\n",
        "!rm -r /content/vosk-model-en-us-0.21\n",
        "!rm -r /content/vosk-model-en-us-0.21.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Retrieved Timestamps"
      ],
      "metadata": {
        "id": "yRzsFWqQJLZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "master_df=pd.read_csv('/content/timestamped_transcripts.csv')\n",
        "master_df['confidence'] = master_df['confidence'].str.strip('%')\n",
        "master_df.columns=(['transcript_id','keyword', 'start_timestamp(seconds)', 'end_timestamp(seconds)', 'confidence_score(percentage)'])\n",
        "master_df.to_csv('timestamped_transcripts.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('timestamped_transcripts.csv') \n",
        "master_df"
      ],
      "metadata": {
        "id": "Bqpi9MaEJKF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Another Speech-To-Text Transcribing"
      ],
      "metadata": {
        "id": "4OPgj6TSggyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "master_df=pd.read_csv('/content/timestamped_transcripts.csv')\n",
        "master_df"
      ],
      "metadata": {
        "id": "pKO1P51UADbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "raw_transcripts=pd.DataFrame()\n",
        "for i in range(25):\n",
        "  content=\"\"\n",
        "  for j in master_df[master_df['transcript_id']==i]['keyword']:\n",
        "    content = content + j + ' '\n",
        "  print(content)\n",
        "  outfile='/content/Raw Transcripts using Vosk/transcript'+str(i)+'.txt'\n",
        "  with open(outfile, \"w\") as text_file:\n",
        "    text_file.write(content)\n",
        "  df2 = pd.DataFrame({'transcript_id':[i] ,'raw_transcript':[content]})\n",
        "  df2['transcript_id'].astype(int)\n",
        "  raw_transcripts = raw_transcripts.append(df2, ignore_index = True)\n",
        "raw_transcripts"
      ],
      "metadata": {
        "id": "4ND7-S97ggN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/Raw Transcripts_using_Vosk.zip /content/Raw\\ Transcripts\\ using\\ Vosk"
      ],
      "metadata": {
        "id": "KiHf_nSeae8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/sample_data/README.md')"
      ],
      "metadata": {
        "id": "H0MmzcAUasgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "transcripts=os.listdir('/content/Raw Transcripts using Vosk')\n",
        "for i in range(len(transcripts)):\n",
        "  transcripts[i]='/content/Raw Transcripts using Vosk/'+transcripts[i]\n",
        "print(transcripts)\n",
        "from google.colab import files\n",
        "for i in transcripts:\n",
        "  files.download(i)"
      ],
      "metadata": {
        "id": "ptUu4tLvobFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_transcripts.to_csv('raw_transcripts_using_vosk.csv')"
      ],
      "metadata": {
        "id": "5CatzW7_vyPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtp_q7wxUGTN"
      },
      "source": [
        "### Random Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgeNeKy71J8y"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qi8wNbDBQ01o"
      },
      "outputs": [],
      "source": [
        "master_df=pd.read_csv('timestamped_transcripts.csv')\n",
        "master_df=master_df.append(df,ignore_index=True)\n",
        "master_df.to_csv('timestamped_transcripts.csv')\n",
        "master_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UREJXU9vk9Y1"
      },
      "outputs": [],
      "source": [
        "master_df=pd.read_csv('timestamped_transcripts.csv')\n",
        "master_df.drop(master_df.columns[0], axis = 1, inplace = True)\n",
        "master_df.to_csv('timestamped_transcripts.csv',index=False)\n",
        "master_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcuOoLE-2G6p"
      },
      "outputs": [],
      "source": [
        "type(list_of_Words)\n",
        "df=pd.DataFrame(list_of_Words)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnXYriNSuOoy"
      },
      "outputs": [],
      "source": [
        "master_list=[]\n",
        "for i in range(len(list_of_Words)):\n",
        "  l=list_of_Words[i].to_string().split(' ')\n",
        "  while \"\" in l:\n",
        "    l.remove(\"\")\n",
        "  master_list.append(l)\n",
        "\n",
        "master_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNR5FnHX1bc6"
      },
      "outputs": [],
      "source": [
        "df=pd.DataFrame(master_list)\n",
        "df=df.drop([1,3,4,6,7,8],axis=1)\n",
        "transcript_id=[1 for i in range(len(master_list))]\n",
        "df.insert(0,'transcript_id',transcript_id)\n",
        "df.columns=['transcript_id','word', 'start_timestamp(sec)', 'end_timestamp(sec)', 'confidence']\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "CrzUTW5CxPnZ",
        "GKdfIn7n0C00",
        "H0PdM38gz9t_",
        "0ss0h0dmHUZN",
        "yRzsFWqQJLZk",
        "4OPgj6TSggyq",
        "rtp_q7wxUGTN"
      ],
      "name": "TigerGraph: TimeStamping using Vosk ",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}